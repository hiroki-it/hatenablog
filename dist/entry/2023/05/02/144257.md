---
Title:【ArgoCD🐙】ArgoCDのアーキテクチャと自動デプロイの仕組み
Category:
  - ArgoCD
  - Microservices Architecture
Date: 2023-05-02T14:42:57+09:00
URL: https://hiroki-hasegawa.hatenablog.jp/entry/2023/05/02/144257
EditURL: https://blog.hatena.ne.jp/hiroki-hasegawa/hiroki-hasegawa.hatenablog.jp/atom/entry/4207575160645284604
Draft: true
---

<br>

[:contents]

<br>

# 01. はじめに

![argocd_rocket.png](https://raw.githubusercontent.com/hiroki-it/tech-notebook-images/master/images/argocd_rocket.png)

ロケットに乗るArgoくんのツラが腹立つわー。

さて最近の業務で、全プロダクトが共通基盤として使用するArgoCDとAWS EKS Clusterのアーキテクチャをリプレイスしています。

採用した設計プラクティスの紹介も兼ねて、ArgoCDのアーキテクチャと自動デプロイの仕組みを記事にしました🚀

ArgoCDは、`kubectl`コマンドによるマニフェストのデプロイを自動化するツールです。

現在に至るまでArgoCDのアーキテクチャには変遷があり、今回紹介するのは執筆時点 (2023/04/30) 時点で最新の `2.6` 系のアーキテクチャです。

アーキテクチャや仕組みはもちろん、個々のマニフェストの実装にもちょっどだけ言及します。

それでは、ArgoCDによるデプロイの仕組みをもりもり布教していきます😗

<br>

# 02. 概要

## アーキテクチャ

#### ▼ レイヤー

まずは、ArgoCDのアーキテクチャのレイヤーがどのようになっているかを見ていきましょう。

ArgoCD公式から、コンポーネント図が公開されています。

図から、次のようなことがわかります👇

- 下位レイヤー向きにしか依存方向がなく、例えばドメインとインフラの間で依存性は逆転させていない。
- レイヤーの種類とそれらの依存方向から、レイヤードアーキテクチャのような構成になっている。
- 特にコアドメインレイヤーが独立したコンポーネントに分割されており、マイクロサービスアーキテクチャを採用している。

![argocd_architecture_layer.png](https://raw.githubusercontent.com/hiroki-it/tech-notebook-images/master/images/argocd_architecture_layer.png)

> ↪️：[https://github.com/argoproj/argo-cd/blob/master/docs/developer-guide/architecture/components.md:title]

<div class="text-box">
ArgoCDのマイクロサービスアーキテクチャは、機能単位の分割方法を採用していると推測しています。
<br>
<br>
本記事では詳しく言及しませんが、マイクロサービスアーキテクチャの分割方法にはいくつか種類があり、境界付けられたコンテキストで分割することがベタープラクティスと言われています😎
<br>
<br>
(境界付けられたコンテキストについても、ちゃんと記事を投稿したい...)
<br>
<blockquote>
↪️：[https://www.amazon.co.jp/dp/4873119316/:title]
<br>
<br>
</blockquote>
</div>

<div class="text-box">
ArgoCDでは、マイクロサービスアーキテクチャの設計図にコンポーネント図を使用しています。
<br>
<br>
コンポーネント図は依存方向 (そのコンポーネントがいずれのコンポーネントを使用するのか) に着目できます。
<br>
<br>
そのため、これはマイクロサービス間の依存方向を視覚化するために有効なUML図です🙆🏻‍♂️
<br>
<blockquote>
↪️：[https://microsoft.github.io/code-with-engineering-playbook/design/diagram-types/DesignDiagramsTemplates/componentDiagrams/:title]
<br>
<br>
</blockquote>
</div>

#### ▼ コンポーネント

次に、コンポーネントの種類を紹介します。

ArgoCDの各コンポーネントが組み合わさり、マニフェストの自動的なデプロイを実現します。

ArgoCD (`2.6`系) のコンポーネントはいくつかあり、主要なコンポーネントの種類とレイヤーは以下の通りです👇

| コンポーネント                   | レイヤー              | 機能                                                                                                                                                                                                            |
| :------------------------------- | --------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| argocd-server (argocd-apiserver) | UI / アプリケーション | みんながよく知るArgoCDのダッシュボードです。<br>また、ArgoCDのAPIとしても機能します。<br>現在、複数のレイヤーの責務を持っており、将来的にUIとアプリケーションは異なるコンポーネントに分割されるかもしれません。 |
| application-controller           | コアドメイン          | Clusterにマニフェストをデプロイします。<br>また、ArgoCD系カスタムリソースのカスタムコントローラーとしても機能します。                                                                                           |
| repo-server                      | コアドメイン          | マニフェスト/チャートリポジトリからクローンを取得します。<br>また、クローンからマニフェストを作成します。                                                                                                       |
| redis-server                     | インフラ              | application-controllerの処理のキャッシュを保管します。                                                                                                                                                          |
| dex-server                       | インフラ              | SSOを採用する場合に、argocd-serverの代わりに認可リクエストを作成し、IDプロバイダーにこれを送信します。<br>これにより、argocd-server上の認証フェーズをIDプロバイダーに委譲できます。                             |

> ↪️：[https://www.amazon.co.jp/dp/1617297275:title]

<br>

### 仕組み

それでは、ArgoCDは、どのようにコンポーネントを組み合わせて、マニフェストをデプロイするのでしょうか？

ここではデプロイ先Cluster管理者 (プロダクト用Clusterを管理するエンジニア) は、ArgoCDのダッシュボードを介してマニフェストをデプロイするとしましょう。

まずは、概要を説明していきます。

![argocd_architecture_introduction.png](https://raw.githubusercontent.com/hiroki-it/tech-notebook-images/master/images/argocd_architecture_introduction.png)

#### 【１】

ArgoCDのCluster上で、repo-serverがマニフェスト/チャートリポジトリのクローンを取得します。

#### 【２】

application-controllerは、repo-serverからマニフェストを取得します。

#### 【３】

application-controllerは、デプロイ先Clusterの現状を確認します。

#### 【４】

application-controllerは、処理結果をredis-serverに保管します。

#### 【５】

argocd-serverは、redis-serverからキャッシュを取得します。

#### 【６】

デプロイ先Cluster管理者は、argocd-serverにログインしようとします。

#### 【７】

argocd-serverは、ログイン時にIDプロバイダーに認可フェーズを委譲するために、dex-serverをコールします。

<div class="text-box">
デプロイ先Cluster管理のログインには、利便性と安全性を兼ね備えたSSOの採用がオススメです。
<br>
<br>
今回の記事では、SSOを採用した場合の仕組みを紹介しています🙇🏻‍♂️
</div>

#### 【８】

dex-serverは、IDプロバイダーに認可リクエストを転送し、IDプロバイダー上で認証フェーズを実施します。

#### 【９】

argocd-serverで認可フェーズを実施します。

ログインが完了し、デプロイ先Cluster管理者は認可スコープに応じてダッシュボードを操作できます。

<div class="text-box">
デプロイ先Clusterの障害の影響範囲を受けないように、これとは独立したClusterで作成した方がよいです。
<br>
<br>
今回の記事では、ArgoCD用Clusterを採用した場合の仕組みを紹介しています🙇🏻‍♂️
</div>

#### 【１０】

application-controllerは、Clusterにマニフェストをデプロイします。

マニフェストのデプロイの仕組みをざっくり紹介しました。

ただこれだと全く面白くないので、各コンポーネントの具体的な処理と、各々がどのように通信しているのかを説明します✌️

<br>

# 03. repo-server

### repo-serverとは

まずは、コアドメインレイヤーにあるrepo-serverです。

マニフェスト/チャートリポジトリ (例：GiHub、GitHub Pages、Artifact Hub、AWS ECR、Artifact Registry、など) からクローンを取得します。

repo-serverを持つPodには、他に軽量コンテナイメージからなるInitContainerとサイドカー (cmp-server) がおり、それぞれ機能が切り分けられています👍

<br>

### 仕組み

![argocd_architecture_repo-server.png](https://raw.githubusercontent.com/hiroki-it/tech-notebook-images/master/images/argocd_architecture_repo-server.png)

#### 【１】

repo-serverの起動時に、InitContainerでお好きなマニフェスト管理ツール (Helm、Kustomize、など) やプラグイン (helm-secrets、KSOPS、SOPS、argocd-vault-plugin、など) をインストールします。

また、軽量コンテナイメージのcmp-serverでは起動時に`/var/run/argocd/argocd-cmp-server`コマンドを実行する必要があり、InitContainer (ここでは`copyutil`コンテナ) を使用して、ArgoCDのコンテナイメージから`argocd-cli`のバイナリファイルをコピーします。

repo-serverのざっくりした実装例は以下の通りです👇

ここでは、ArgoCDで使いたいツール (Helm、SOPS、helm-secrets) をInitContainerでインストールしています。

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: argocd-repo-server
  namespace: argocd
spec:
  containers:
    - name: repo-server
      image: quay.io/argoproj/argocd:latest

  initContainers:
    # お好きなツールをインストールするInitContainer
    - name: helm-installer
      image: alpine:latest
      command:
        - /bin/sh
        - -c
      args:
        - |
          # インストール処理
      volumeMounts:
        - mountPath: /custom-tools
          name: custom-tools
    - name: sops-installer
      image: alpine:latest
      command:
        - /bin/sh
        - -c
      args:
        - |
          # インストール処理
      volumeMounts:
        - mountPath: /custom-tools
          name: custom-tools
    - name: helm-secrets-installer
      image: alpine:latest
      command:
        - /bin/sh
        - -c
      args:
        - |
          # インストール処理
      volumeMounts:
        - mountPath: /helm-working-dir/plugins
          name: helm-working-dir

    ...

    # cmp-serverにargocd-cliのバイナリをコピーするInitContainer
    - name: copyutil
      image: quay.io/argoproj/argocd:latest
      command:
        - cp
        - -n
        - /usr/local/bin/argocd
        - /var/run/argocd/argocd-cmp-server
      volumeMounts:
        - name: var-files
          mountPath: /var/run/argocd

  # Podの共有ボリューム
  volumes:
    - name: custom-tools
      emptyDir: {}
    - name: var-files
      emptyDir: {}
```

> ↪️：[https://argo-cd.readthedocs.io/en/stable/operator-manual/custom_tools/#adding-tools-via-volume-mounts:title]

<div class="text-box">
ArgoCDのコンテナイメージ (<code>quay.io/argoproj/argocd</code>) には、いくつかのツール (例：Helm、Kustomize、Ks、Jsonnet、など) があらかじめインストールされています。
<br>
<br>
そのため、サイドカーのcmp-serverを採用しない場合は、これらのツールをインストールする必要はありません。
<br>
<br>
反対に、cmp-serverを採用する場合は、インストールが必要になります🙇🏻‍
<br>
<blockquote>
↪️：[https://argo-cd.readthedocs.io/en/stable/operator-manual/custom_tools/#custom-tooling:title]
<br>
<br>
</blockquote>
</div>

#### 【２】

repo-serverは、Secret (argocd-repo-creds) からリポジトリの認証情報を取得します。

argocd-repo-credsではリポジトリの認証情報のテンプレートを管理しています。

指定した文字列から始まる (最長一致) URLを持つリポジトリに接続する場合に、それらの接続で認証情報を一括して適用できます。

argocd-repo-credsのざっくりした実装例は以下の通りです👇

ここでは、リポジトリのSSH公開鍵認証を採用し、argocd-repo-credsに共通の秘密鍵を設定しています。

```yaml
apiVersion: v1
kind: Secret
metadata:
  name: argocd-repo-creds-github
  namespace: argocd
  labels:
    argocd.argoproj.io/secret-type: repo-creds
type: Opaque
data:
  type: git
  url: https://github.com/hiroki-hasegawa
  # 秘密鍵
  sshPrivateKey: |
    MIIC2 ...
```

あとは、各リポジトリのSecret (argocd-repo) にURLを設定しておきます。

すると、先ほどのargocd-repo-credsのURLに最長一致するURLを持つSecretには、一括して秘密鍵が適用されます。

```yaml
# foo-repositoryをポーリングするためのargocd-repo
apiVersion: v1
kind: Secret
metadata:
  namespace: argocd
  name: foo-argocd-repo
  labels:
    argocd.argoproj.io/secret-type: repository
type: Opaque
data:
  # 認証情報は設定しない。
  # マニフェストリポジトリ名
  name: foo-repository
  # https://github.com/hiroki-hasegawa に最長一致する。
  url: https://github.com/hiroki-hasegawa/foo-manifest.git
---
# bar-repositoryをポーリングするためのargocd-repo
apiVersion: v1
kind: Secret
metadata:
  namespace: argocd
  name: bar-argocd-repo
  labels:
    argocd.argoproj.io/secret-type: repository
type: Opaque
data:
  # 認証情報は設定しない。
  # マニフェストリポジトリ名
  name: bar-repository
  # https://github.com/hiroki-hasegawa に最長一致する。
  url: https://github.com/hiroki-hasegawa/bar-manifest.git
```

> ↪️：[https://argo-cd.readthedocs.io/en/stable/operator-manual/declarative-setup/#repository-credentials:title]

#### 【３】

repo-serverは、認証情報を使用して、リポジトリに`git clone`コマンドを実行します。

取得したクローンを、`/tmp/_argocd-repo`ディレクトリ配下にUUIDの名前で保管します。

また、リポジトリの変更をポーリングし、変更を検知した場合は`git fetch`コマンドを実行します。

```sh
# クローンが保管されていることを確認できる
$ kubectl -it exec argocd-repo-server \
    -c repo-server \
    -n foo \
    -- bash -c "ls /tmp/_argocd-repo/<URLに基づくUUID>"

# リポジトリ内のファイル
Chart.yaml  README.md  templates  values.yaml
```

> ↪️：[https://github.com/argoproj/argo-cd/discussions/9889#discussioncomment-3093809:title]

<div class="text-box">
<code>2.3</code>以前では、repo-serverは、リポジトリのクローンは<code>/tmp</code>ディレクトリ配下に、URLに基づく名前で保管します。
<br>

```sh
$ kubectl -it exec argocd-repo-server \
    -c repo-server \
    -n foo \
    -- bash -c "ls /tmp/https___github.com_hiroki-hasegawa_foo-repository"

# リポジトリ内のファイル
Chart.yaml  README.md  templates  values.yaml
```

</div>

#### 【４】

repo-serverは、Volume上のUnixドメインソケットを介して、サイドカー (cmp-server) によるプラグインの実行をコールします。

Unixドメインソケットのエンドポイントの実体は`.sock`ファイルです。

```sh
$ kubectl exec -it argocd-repo-server -c foo-plugin-cmp-server\
    -- bash -c "ls /home/argocd/cmp-server/plugins/"

foo-plugin.sock
```

<div class="text-box">
Unixソケットドメインは、同じOS上のファイルシステムを介して、データを直接的に送受信する仕組みです。
<br>
<br>
Unixソケットドメインを使用すると、同じVolumeがマウントされたコンテナのプロセス間で、データを送受信できます👍
<br>
<blockquote>
↪️：[https://ascii.jp/elem/000/001/415/1415088/:title]
<br>
<br>
</blockquote>
</div>

#### 【５】

cmp-serverは、暗号化キー (例：AWS KMS、Google CKM、など) を使用してSecretストア (AWS SecretManager、Google SecretManager、SOPS、Vault、など) の暗号化変数を復号化します。

#### 【６】

cmp-serverがマニフェスト管理ツール (例：Helm、Kustomize) でマニフェストを作成する時に、これのプラグイン (helm-secrets、argocd-vault-plugin、など) を使用したいようなユースケースがあるかと思います。

マニフェストの作成時の追加処理として、ConfigMap配下のConfigManagementPluginでプラグインの処理を定義します。

ざっくりした実装例は以下の通りです👇

ここでは、プラグインとしてhelm-secretsを採用し、`helm secrets template`コマンドの実行を定義します。

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: argocd-cmp-cm
  namespace: argocd
data:
  helm-secrets-plugin.yaml: |
    apiVersion: argoproj.io/v1alpha1
    kind: ConfigManagementPlugin
    metadata:
      namespace: argocd
      name: helm-secrets
    spec:
      generate:
        command:
          - /bin/bash
          - -c
        args:
          - |
            set -o pipefail
            helm secrets template -f $ARGOCD_ENV_SECRETS -f $ARGOCD_ENV_VALUES -n $ARGOCD_APP_NAMESPACE $ARGOCD_APP_NAME .
  foo-plugin.yaml: |
    ...
```

<div class="text-box">
複数のConfigManagementPluginのマニフェストを定義できるように、各ConfigManagementPluginで異なるファイル名とし、ConfigMapで管理すると良いです👍
</div>

#### 【７】

cmp-serverは、を実行し、Secretを含むマニフェストを作成します。

ConfigMap配下のファイルを “plugin.yaml” の名前でサイドカーにマウントする必要があります。

また、先ほどのUnixドメインソケットの`.sock`ファイルや、 cmp-serverがプラグインを実行するための各種バイナリファイルもマウントが必要です。

ざっくりした実装例は以下の通りです👇

ここでは、`helm-secrets`プラグインを実行するサイドカー (helm-secrets-cmp-server) を作成します。

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: argocd-repo-server
spec:
  containers:
    # repo-server
    - name: repo-server
      image: quay.io/argoproj/argocd:latest

    ...

    # helm-secretsのcmp-server
    - name: helm-secrets-cmp-server
      # コンテナイメージは軽量にする
      image: ubuntu:latest
      command:
        - /var/run/argocd/argocd-cmp-server
      env:
        # helmプラグインの場所を設定する
        - name: HELM_PLUGINS
          value: /helm-working-dir/plugins
      securityContext:
        runAsNonRoot: true
        runAsUser: 999
      volumeMounts:
        # リポジトリのクローンをコンテナにマウントする
        - name: tmp
          mountPath: /tmp
        # ConfigManagementPluginのマニフェスト (helm-secrets.yaml) を "plugin.yaml" の名前でコンテナにマウントする
        - name: argocd-cmp-cm
          mountPath: /home/argocd/cmp-server/config/plugin.yaml
          subPath: helm-secrets.yaml
        # コンテナ間で通信するためのUnixドメインソケットファイルをコンテナにマウントする
        - name: plugins
          mountPath: /home/argocd/cmp-server/plugins
        # Helmなどの任意のツールのバイナリファイルをコンテナにマウントする
        - name: custom-tools
          subPath: helm
          mountPath: /usr/local/bin/helm
        - name: custom-tools
          subPath: sops
          mountPath: /usr/local/bin/sops
        # helmプラグインのバイナリをコンテナにマウントする
        - name: helm-working-dir
          mountPath: /helm-working-dir/plugins

      ...

  # Podの共有ボリューム
  volumes:
    # リポジトリのクローンを含む
    - name: tmp
      emptyDir: {}
    # Helmなどの任意のツールを含む
    - name: custom-tools
      emptyDir: {}
    # helmプラグインを含む
    - name: helm-working-dir
      emptyDir: {}
```

<div class="text-box">
ArgoCDの<code>v2.6</code>では、ConfigManagementPluginのマニフェストを<code>/home/argocd/cmp-server/config</code>ディレクトリに、<code>plugin.yaml</code>に名前でマウントしないといけません。
<br>
<br>
これは、cmp-serverの起動コマンド (<code>/var/run/argocd/argocd-cmp-server</code>) が<code>plugin.yaml</code>の名前しか扱えないためです。
<br>
<br>
今後のアップグレードで改善される可能性がありますが、<code>v2.6</code>では、ConfigManagementPluginの数だけcmp-serverが必要になってしまいます🙇🏻‍♂️
<br>
</div>

<div class="text-box">
今回は詳しく言及しませんが、クラウドプロバイダーのSecretストアの変数を使用する場合は、Secretのデータ注入ツールのプラグイン (特にargocd-vault-plugin) は必須ではありません。
<br>
<br>
この場合、代わりにSecretsストアCSIドライバーやExternalSecretsOperatorを使用できます。
<br>
<br>
これらは、クラウドプロバイダーから変数を取得し、これをSecretにデータとして注入してくれます🙇🏻‍
<br>
<blockquote>
↪️：[https://akuity.io/blog/how-to-manage-kubernetes-secrets-gitops/:title]
<br>
<br>
</blockquote>
</div>

<br>

# 04. application-controller、redis-server

### application-controllerとは

コアドメインレイヤーにあるapplication-controllerです。

Clusterにマニフェストをデプロイします。

また、ArgoCD系カスタムリソースのカスタムコントローラーとしても機能します。

<br>

### redis-serverとは

インフラレイヤーにあるredis-serverです。

application-controllerの処理のキャッシュを保管します。

<br>

### 仕組み

![argocd_architecture_application-controller.png](https://raw.githubusercontent.com/hiroki-it/tech-notebook-images/master/images/argocd_architecture_application-controller.png)

#### 【１】

ArgoCD用Clusterの管理者は、ClusterにArgoCD系のカスタムリソース (例：Application、AppProject、など)　をデプロイします。

<div class="text-box">
『卵が先か、ニワトリが先か？』みたいな話ですが、ArgoCD自体はArgoCD以外でデプロイする必要があります。
<br>
<br>
この時、argo-helmを使用すると簡単にArgoCDのマニフェストを作成できます。
<br>
<br>
ただ注意点があり、Helmの重要な仕様として、HelmはCRDを作成できる一方でこれを変更できません。
<br>
<br>
HelmでCRDを作成するとHelmの管理ラベルが挿入されてしまうため、作成の時点からCRDがHelmの管理外となるように、<code>kubectl</code>コマンドでこれを作成した方がよいです👍
<br>

```sh
$ kubectl diff -k "https://github.com/argoproj/argo-cd/manifests/crds?ref=<バージョンタグ>"

$ kubectl apply -k "https://github.com/argoproj/argo-cd/manifests/crds?ref=<バージョンタグ>"
```

<blockquote>
️↪️：[https://github.com/argoproj/argo-helm:title]
<br>
<br>
</blockquote>
</div>

#### 【２】

kube-controller-managerは、application-controllerを操作し、Reconciliationを実施します。

application-controllerは、Etcd上に永続化されたマニフェストと同じ状態のカスタムリソースを作成/変更します。

<div class="text-box">
先に記載したと通り、application-controllerはカスタムコントローラーとしても機能します。
<br>
<br>
本記事では詳しく言及しませんが、カスタムコントローラーの仕組みやCRDとの関係については、以下の記事が非常に参考になりました🙇🏻‍
<br>
<blockquote>
️↪️：[https://developers.redhat.com/articles/2021/06/22/kubernetes-operators-101-part-2-how-operators-work:title]#the_kubernetes_architecture
<br>
<br>
</blockquote>
</div>

#### 【３】

application-controllerは、repo-serverからリポジトリのマニフェストを取得します。

取得したマニフェストは、repo-serverのサイドカーであるcmp-serverが作成したものです。

#### 【４】

application-controllerは、デプロイ先Clusterをヘルスチェックします。

application-controllerには、gitops-engineパッケージが内蔵されており、これはヘルスチェックからデプロイまでの基本的な処理を実行します。

<div class="text-box">
gitops-engineは、ArgoCDのデプロイに必要な処理を揃えたパッケージです。
<br>
<br>

執筆時点 (2023/04/30) では以下のディレクトリからなります👇

```yaml
gitops-engine/
├── pkg
│   ├── cache
│   ├── diff   # リポジトリとClusterの間のマニフェストの差分を検出する。ArgoCDのDiff機能に相当する。
│   ├── engine # 他のパッケージを使い、GitOpsの一連の処理を実行する。
│   ├── health # Clusterのステータスをチェックする。ArgoCDのヘルスチェック機能に相当する。
│   ├── sync   # Clusterにマニフェストをデプロイする。ArgoCDのSync機能に相当する。
│   └── utils  # 他のパッケージに汎用的な関数を提供する。
│
...
```

<blockquote>
↪️：[https://github.com/argoproj/gitops-engine/blob/master/specs/design-top-down.md#design-details:title]
<br>
<br>
</blockquote>

</div>

#### 【５】

application-controllerは、デプロイ先Clusterのマニフェストと、repo-serverから取得したマニフェストの差分を検出します。

ここで、`kubectl diff`コマンドの実行が自動化されています。

#### 【６】

application-controllerは、処理結果をredis-serverに保管します。

redis-serverは、Applicationやリポジトリのコミットの単位で、application-controllerの処理結果を保管しています。

```sh
$ kubectl exec -it argocd-redis-server \
    -n foo \
    -- sh -c "redis-cli --raw"

127.0.0.1:6379> keys *

...

app|resources-tree|<Application名>|<キャッシュバージョン>
cluster|info|<デプロイ先ClusterのURL>|<キャッシュバージョン>
git-refs|<マニフェスト/チャートリポジトリのURL>|<キャッシュバージョン>
mfst|app.kubernetes.io/instance|<Application名>|<最新のコミットハッシュ値>|<デプロイ先Namespace>|*****|<キャッシュバージョン>

...

```

#### 【７】

application-controllerは、Applicationの操作に応じて、Clusterにマニフェストをデプロイします。

ここで、`kubectl apply`コマンドの実行が自動化されています。

<div class="text-box">
Kubernetesリソースのマニフェストには、<code>metadata.managedFields</code>キーがあり、何がそのマニフェストを作成/変更したのかを確認できます。
<br>
<br>
実際にマニフェストを確認してみると、確かにapplication-controllerがマニフェストを作成/変更してくれたことを確認できます。

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  managedFields:
    # ArgoCDのapplication-controllerによる管理
    - manager: argocd-application-controller
      apiVersion: apps/v1
      # kube-apiserverに対するリクエスト内容
      operation: Update
      time: "2022-01-01T16:00:00.000Z"
      # ArgoCDのapplication-controllerが管理するマニフェストのキー部分
      fields: ...
```

<blockquote>
️↪️：[https://kubernetes.io/docs/reference/using-api/server-side-apply/#field-management:title]
<br>
<br>
</blockquote>
</div>

<br>

# 05. dex-server

### dex-serverとは

インフラレイヤーにあるdex-serverです。

SSO (例：OAuth `2.0`、SAML、OIDC) を採用する場合に、argocd-serverの代わりに認可リクエストを作成し、IDプロバイダー (例：GitHub、KeyCloak、AWS Cognito、Google Auth、など) にこれを送信します。

これにより、argocd-server上の認証フェーズをIDプロバイダーに委譲できます。

> ↪️：[https://github.com/dexidp/dex#connectors:title]

<div class="text-box">
dex-serverを使わずに、argocd-serverからIDプロバイダーに認可リクエストを直接的に送信することもできます。
<br>
<br>
執筆時点 (2023/04/30) で、argocd-serverは、特にOIDCだけは処理できるため、ログイン要件がOIDCの場合は、dex-serverを必ずしも採用してなくもよいです。
<br>
<br>
言い換えれば、その他のSSO (例：OAuth <code>2.0</code>、SAML) を使用する場合は、dex-serverを採用する必要があります👍
<br>
<br>
<blockquote>
️↪️：[https://argo-cd.readthedocs.io/en/stable/operator-manual/user-management/#sso:title]
<br>
<br>
</blockquote>
</div>

<br>

### 仕組み

![argocd_architecture_dex-server.png](https://raw.githubusercontent.com/hiroki-it/tech-notebook-images/master/images/argocd_architecture_dex-server.png)

#### 【１】

デプロイ先Cluster管理者がダッシュボード (argocd-server) にSSOを使用してログインしようとします。

#### 【２】

argocd-serverは、認証フェーズをIDプロバイダーに委譲するために、dex-serverをコールします。

<div class="text-box">
argocd-serverの認証認可処理は、AuthN (認証) と AuthZ (認可) から構成されています。
<br>
<br>
認証フェーズを委譲しない場合、このAuthNにて、デプロイ先Cluster管理者をユーザーやグループとして認証します👍
<br>
<br>
<img src="https://raw.githubusercontent.com/hiroki-it/tech-notebook-images/master/images/argocd_auth_architecture.jpg" alt="argocd_auth_architecture" />
<blockquote>
️↪️：[https://github.com/argoproj/argo-cd/blob/master/docs/developer-guide/architecture/authz-authn.md:title]
<br>
<br>
</blockquote>
</div>

#### 【３】

dex-serverは、認可リクエストを作成し、IDプロバイダーにこれを送信します。

認可リクエストに必要な情報は、ConfigMap (argocd-cm) で設定しておく必要があります。

argocd-cmのざっくりした実装例は以下の通りです👇

ここでは、IDプロバイダーをGitHubとし、認可リクエストに必要なクライアントIDとクライアントシークレットを設定しています。

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  namespace: argocd
  name: argocd-cm
data:
  dex.config: |
    connectors:
      - type: github
        id: github
        name: GitHub SSO
        config:
          clientID: *****
          clientSecret: *****
        # 委譲先のIDプロバイダーがリクエストを待ち受けるURLを設定する。
        redirectURI: https://example.com/api/dex
```

#### 【４】

dex-serverは、IDプロバイダーに認可リクエストを転送し、IDプロバイダー上で認証フェーズを実施します。

#### 【５】

IDプロバイダー側でSSOの認証フェーズを実施します。

コールバックURL宛 (argocd-server) に認可レスポンスを送信します。

#### 【６】

argocd-serverは、AuthZで認可フェーズを実施します。

ConfigMap (argocd-rbac-cm) を参照し、IDプロバイダーから取得したユーザーやグループに認可スコープを付与します。

ざっくりした実装例は以下の通りです👇

ここでは、developerロールには`dev`というAppProjectのみ、またmaintainerロールには全てのAppProjectの操作を許可しています。

また、これらのロールをIDプロバイダーから取得したグループに紐づけています。

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: argocd-rbac-cm
  namespace: argocd
data:
  # デフォルトのロール
  policy.default: role:developer
  policy.csv: |
    # ロールに認可スコープを紐付ける。
    p, role:developer, *, *, dev/*, allow
    p, role:maintainer, *, *, *, allow

    # グループにロールを紐付ける。
    g, developers, role:developer
    g, maintainers, role:maintainer
  scopes: "[groups]"
```

<div class="text-box">
ConfigMap (argocd-rbac-cm) の認可スコープの定義には、Casbinの記法を使用します。
<br>
<br>
今回の実装例で使用した<code>p</code>と<code>g</code>では、以下を定義できます。
<br>
<br>
<table>
    <tr>
        <th>記号</th>
        <th>説明</th>
        <th>記法</th>
    </tr>
    <tr>
        <td><code>p</code> (パーミッション) </td>
        <td>ロールと認可スコープを定義する。代わりに、RoleやClusterRoleでも定義できる。</td>
        <td><code>p, &lt;ロール名&gt; &lt;Kubernetesリソースの種類&gt; &lt;アクション名&gt; &lt;プロジェクト名&gt;/&lt;Kubernetesリソースの識別名&gt;</code></td>
    </tr>
    <tr>
        <td><code>g</code> (グループ) </td>
        <td>グループにロールを紐付ける。</td>
        <td><code>g, &lt;グループ名&gt; &lt;ロール名&gt;</code></td>
    </tr>
</table>
<blockquote>
↪️：[https://argo-cd.readthedocs.io/en/stable/operator-manual/rbac/:title]
<br>
<br>
</blockquote>
</div>

<br>

# 06. argocd-server (argocd-apiserver)

### argocd-serverとは

最後に、インフラレイヤーにあるargocd-serverです。

『argocd-apiserver』とも呼ばれます。

みんながよく知るArgoCDのダッシュボードです。

また、ArgoCDのAPIとしても機能し、他のコンポーネントと通信します🦄

<br>

### 仕組み

![argocd_architecture_argocd-apiserver.png](https://raw.githubusercontent.com/hiroki-it/tech-notebook-images/master/images/argocd_architecture_argocd-server.png)

#### 【１】

application-controllerは、デプロイ先Clusterをヘルスチェックします。

#### 【２】

application-controllerは、デプロイ先Clusterのマニフェストと、ポーリング対象のリポジトリのマニフェストの差分を検出します。

#### 【３】

application-controllerは、処理結果をredis-serverに保管します。

#### 【４】

argocd-serverは、redis-serverから処理結果を取得します。

#### 【５】

デプロイ先Cluster管理者がダッシュボード (argocd-server) にSSOを使用してログインしようとします。

#### 【６】

Ingressコントローラーは、Ingressのルーティングルールを参照し、argocd-serverにルーティングします。

#### 【７】

argocd-serverは、ログイン時にIDプロバイダーに認可フェーズを委譲するために、dex-serverをコールします。

#### 【８】

IDプロバイダー上で認証フェーズが完了します。

argocd-serverは、ConfigMap (argocd-rbac-cm) を参照し、デプロイ先Cluster管理者に認可スコープを付与します。

#### 【９】

argocd-serverは、認可スコープに応じて、デプロイ先Cluster管理者がApplicationを操作できるようにします。

<div class="text-box">
認可スコープの制御として、AppProjectを活用すると良いです。
<br>
<br>
その場合、デプロイ先Cluster管理者にどの程度の大きさの認可スコープを付与したいのかに応じて、AppProjectを作成するとよいです。
<br>
<br>
例えば、特定のプロダクト用Clusterや、限られた実行環境のみを操作できるようにする、などのスコープがあります。
<br>
<br>
AppProjectを作成した上で、先ほどのConfigMap (argocd-rbac-cm) の実装例でも紹介したように、ロールごとに特定のAppProjectへの操作を許可します。
<br>
<br>
私の携わっている業務では、本番環境のデプロイ先Clusterの操作を制限するために、実行環境別にAppProjectを作成しています✌️
<br>
</div>

#### 【１０】

デプロイ先Cluster管理者は、ダッシュボード (argocd-server) を使用して、ClusterにマニフェストをSyncします。

この時、Applicationを介してapplication-controllerを操作し、マニフェストをデプロイします。

図では、App-Of-Appsパターンを採用したと仮定しています👨‍👩‍👧‍👦

<div class="text-box">
ArgoCDにはApp-Of-Appsパターンというデザインパターンがあります。
<br>
<br>
これを使用すると、各Application配下のマニフェストをより疎結合に管理できます✌️
<br>
<br>
例えば以下の画像の通り、最上位のApplication配下に、領域別のApplicationを配置します (アプリ領域のApplication、インフラ領域のそれ) 。
<br>
<br>
その後、両方のApplication配下にさらにチャート別の子Applicationを分割し、チャートのデプロイを管理します。
<br>
<br>
アプリ領域の子Applicationではアプリコンテナのチャート、インフラ領域の子Applicationでは監視/ネットワーク/ハードウェアリソース管理系のチャートを管理します👍
<br>
<br>
<img src="https://raw.githubusercontent.com/hiroki-it/helm-charts-practice/main/root-application.png" alt="root-application" style="zoom:80%;" />
</div>

<br>

# 07. アーキテクチャのまとめ

今までの全ての情報をざっくり整理して簡略化すると、ArgoCDは以下の仕組みでマニフェストをデプロイすることになります👇

![argocd_architecture.png](https://raw.githubusercontent.com/hiroki-it/tech-notebook-images/master/images/argocd_architecture.png)

<br>

# 08. おわりに

ArgoCDによるデプロイの仕組みの仕組みをもりもり布教しました。

ArgoCDは、UIが使いやすく、仕組みの詳細を知らずとも比較的簡単に運用できるため、ユーザーフレンドリーなツールだと思っています。

もしArgoCDを使わずにマニフェストをデプロイしている方は、ArgoCDの採用をハイパー・ウルトラ・アルティメットおすすめします👍

なお、登場した設計プラクティスのいくつかは、以下の書籍にも記載されていますので、ぜひご一読いただけると。

> ↪️：
>
> - [https://www.amazon.co.jp/dp/B0BQL1CBPX:title]
> - [https://www.amazon.co.jp/dp/180323332X:title]

<br>

# 謝辞

ArgoCDの設計にあたり、[`@yaml_villager`](https://twitter.com/yaml_villager?s=20) さんに有益なプラクティスをご教授いただきました。

この場で感謝申し上げます🙇🏻‍

<br>
